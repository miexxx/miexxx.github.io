<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://miexxx.github.io</id>
    <title>Great Wei</title>
    <updated>2020-10-13T12:49:34.573Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://miexxx.github.io"/>
    <link rel="self" href="https://miexxx.github.io/atom.xml"/>
    <subtitle>awsl</subtitle>
    <logo>https://miexxx.github.io/images/avatar.png</logo>
    <icon>https://miexxx.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Great Wei</rights>
    <entry>
        <title type="html"><![CDATA[Prometheus监控告警系统]]></title>
        <id>https://miexxx.github.io/post/prometheus-jian-kong-gao-jing-xi-tong/</id>
        <link href="https://miexxx.github.io/post/prometheus-jian-kong-gao-jing-xi-tong/">
        </link>
        <updated>2020-10-12T08:18:46.000Z</updated>
        <content type="html"><![CDATA[<h1 id="什么是prometheus">什么是prometheus</h1>
<p>Prometheus是由SoundCloud开发的开源监控报警系统和时序列数据库(TSDB)。Prometheus使用Go语言开发，是Google BorgMon监控系统的开源版本。<br>
2016年由Google发起Linux基金会旗下的原生云基金会(Cloud Native Computing Foundation), 将Prometheus纳入其下第二大开源项目。<br>
Prometheus目前在开源社区相当活跃。<br>
Prometheus和Heapster(Heapster是K8S的一个子项目，用于获取集群的性能数据。)相比功能更完善、更全面。Prometheus性能也足够支撑上万台规模的集群。</p>
<h1 id="prometheus的特点">prometheus的特点</h1>
<p>多维度数据模型。<br>
灵活的查询语言。<br>
不依赖分布式存储，单个服务器节点是自主的。<br>
通过基于HTTP的pull方式采集时序数据。<br>
可以通过中间网关进行时序列数据推送。<br>
通过服务发现或者静态配置来发现目标服务对象。<br>
支持多种多样的图表和界面展示，比如Grafana等。</p>
<h1 id="基本原理">基本原理</h1>
<p>Prometheus的基本原理是通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。输出被监控组件信息的HTTP接口被叫做exporter 。目前互联网公司常用的组件大部分都有exporter可以直接使用，比如Varnish、Haproxy、Nginx、MySQL、Linux系统信息(包括磁盘、内存、CPU、网络等等)。</p>
<h1 id="服务过程">服务过程</h1>
<p>Prometheus Daemon负责定时去目标上抓取metrics(指标)数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。Prometheus支持通过配置文件、文本文件、Zookeeper、Consul、DNS SRV Lookup等方式指定抓取目标。Prometheus采用PULL的方式进行监控，即服务器可以直接通过目标PULL数据或者间接地通过中间网关来Push数据。<br>
Prometheus在本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。<br>
Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，例如Grafana、自带的Promdash以及自身提供的模版引擎等等。Prometheus还提供HTTP API的查询方式，自定义所需要的输出。<br>
PushGateway支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。<br>
Alertmanager是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。</p>
<h1 id="docker-stack-配置服务">docker-stack 配置服务</h1>
<pre><code>version: '3.7'

volumes:
    prometheus_data: {}
    grafana_data: {}

networks:
  monitor-net:

services:
  webhook-dingding:
    image: timonwong/prometheus-webhook-dingtalk
    command: 
      - '--web.enable-ui'
      - '--config.file=/etc/prometheus-webhook-dingtalk/config.yml'
    volumes:
      - ./webhook/config.yml:/etc/prometheus-webhook-dingtalk/config.yml
    ports:
      - 8060:8060
    networks:
      - monitor-net
    restart: always
    deploy:
      mode: global
      restart_policy:
          condition: any

  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus/:/etc/prometheus/
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - 9090:9090
    depends_on:
      - cadvisor
    networks:
      - monitor-net
    deploy:
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any

  node-exporter:
    image: prom/node-exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command: 
      - '--path.procfs=/host/proc' 
      - '--path.sysfs=/host/sys'
      - --collector.filesystem.ignored-mount-points
      - &quot;^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)&quot;
    ports:
      - 9100:9100
    networks:
      - monitor-net
    deploy:
      mode: global
      restart_policy:
          condition: any

  kafka-exporter:
    image: danielqsj/kafka-exporter
    command: 
      - '--kafka.server=172.31.0.117:9092'
      - '--kafka.server=172.31.0.117:9093'
    ports:
      - 9308:9308
    networks:
      - monitor-net
    restart: always
    deploy:
      mode: global
      restart_policy:
          condition: any

  alertmanager:
    image: prom/alertmanager
    ports:
      - 9093:9093
    volumes:
      - &quot;./alertmanager/:/etc/alertmanager/&quot;
    networks:
      - monitor-net
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    deploy:
      placement:
        constraints:
           - node.role==manager
      restart_policy:
        condition: any  

  cadvisor:
    image: google/cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    ports:
      - 8080:8080
    networks:
      - monitor-net
    deploy:
      mode: global
      restart_policy:
          condition: any

  grafana:
    image: grafana/grafana
    depends_on:
      - prometheus
    ports:
      - 3000:3000
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/:/etc/grafana/provisioning/
      - ./grafana/:/etc/grafana/
    env_file:
      - ./grafana/config.monitoring
    networks:
      - monitor-net
    user: &quot;472&quot;
    deploy:
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
</code></pre>
<p>其中kafka_exporter与webhook-dingding 是可选服务，这里主要是用于kafka集群的监控与告警使用。</p>
<h1 id="配置">配置</h1>
<h2 id="prometheus-配置文件prometheusyml">prometheus 配置文件（prometheus.yml）</h2>
<pre><code># my global config
global:
  scrape_interval:     15s # By default, scrape targets every 15 seconds.
  evaluation_interval: 15s # By default, scrape targets every 15 seconds.
  # scrape_timeout is set to the global default (10s).

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
      monitor: '监控系统'

# Load and evaluate rules in this file every 'evaluation_interval' seconds.
rule_files:
  - 'alert.rules'
  # - &quot;first.rules&quot;
  # - &quot;second.rules&quot;

# alert
alerting:
  alertmanagers:
  - scheme: http
    static_configs:
    - targets:
      - &quot;alertmanager:9093&quot;

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.

  - job_name: 'prometheus'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    static_configs:
         - targets: ['172.31.0.144:9090']

  - job_name: 'kafka-exporter'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s
    static_configs:
         - targets: ['172.31.0.144:9308']

  - job_name: 'cadvisor'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    dns_sd_configs:
    - names:
      - 'tasks.cadvisor'
      type: 'A'
      port: 8080

#     static_configs:
#          - targets: ['cadvisor:8080']

  - job_name: 'node-exporter'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s
    static_configs:
         - targets: ['172.31.0.144:9100','172.31.0.136:9099','172.31.0.117:9099','172.31.0.118:9099']
</code></pre>
<p>这里主要配置一些exporter服务，主要用来提供数据，用于分析监控。</p>
<h2 id="prometheus-配置文件alterrules">prometheus 配置文件（alter.rules）</h2>
<pre><code>groups:
- name: 服务告警
  rules:

  - alert: 服务异常关闭
    expr: up == 0
    for: 1m
    labels:
      severity: prometheus
    annotations:
      summary: &quot;prometheus实例关闭&quot;
      description: &quot;{{ $labels.instance }} of job {{ $labels.job }} 已经关闭了!!!!&quot;

  - alert: 消息积压
    expr: kafka_consumergroup_lag &gt; 30
    for: 1m
    labels:
      severity: kafka
    annotations:
      summary: &quot;kafka消息积压&quot;
      description: &quot;kafka 消费组 {{ $labels.consumergroup }} \n\r topic: {{ $labels.topic }} \n\r 消息积压数: {{ $value }}&quot;

  - alert: CPU告警
    expr: (1 - avg(irate(node_cpu_seconds_total{mode=&quot;idle&quot;}[5m])) by (instance)) * 100 &gt; 90
    for: 1m
    labels:
      team: node
    annotations:
      summary: &quot;CPU告警&quot;
      description: &quot;机器(ip = {{$labels.instance}}) \n\r CPU使用量超过90%，目前剩余量为：{{ $value }}&quot;

  - alert: 磁盘告警
    expr: 100.0 - 100 * ((node_filesystem_avail_bytes{mountpoint=~&quot;/&quot;, device!=&quot;rootfs&quot;} / 1000 / 1000 ) / (node_filesystem_size_bytes{mountpoint=~&quot;/&quot;, device!=&quot;rootfs&quot;} / 1024 / 1024)) &gt; 85
    for: 1m
    labels:
      team: node
    annotations:
      summary: &quot;磁盘告警&quot;
      description: &quot;机器(ip = {{$labels.instance}}) \n\r 磁盘使用量超过85%，目前剩余量为：{{ $value }}G &quot;

  - alert: 内存告警
    expr: (node_memory_MemTotal_bytes - (node_memory_MemFree_bytes+node_memory_Buffers_bytes+node_memory_Cached_bytes)) / node_memory_MemTotal_bytes * 100 &gt; 90
    for: 1m
    labels:
      team: node
    annotations:
      summary: &quot;内存告警&quot;
      description: &quot;机器(ip = {{$labels.instance}}) \n\r 内存使用量超过90%，目前剩余量为：{{ $value }}M &quot;

</code></pre>
<p>以上是自定义的各种告警指标。</p>
<h2 id="alertmanager配置文件configyml">alertmanager配置文件(config.yml)</h2>
<pre><code> route:
     receiver: 'web.hook'
 receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: http://172.31.0.144:8060/dingtalk/webhook1/send
</code></pre>
<p>这里将会将告警信息发送到指定告警api，可自定义webhook服务，处理告警消息内容。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MQTT协议详解]]></title>
        <id>https://miexxx.github.io/post/mqtt-xie-yi-xiang-jie/</id>
        <link href="https://miexxx.github.io/post/mqtt-xie-yi-xiang-jie/">
        </link>
        <updated>2020-05-25T08:18:07.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mqtt是什么">MQTT是什么？</h1>
<p>MQTT（Message Queuing Telemetry Transport，消息队列遥测传输协议），是一种基于发布/订阅（Publish/Subscribe）模式的轻量级通讯协议，该协议构建于TCP/IP协议上，由IBM在1999年发布，目前最新版本为v3.1.1。MQTT最大的优点在于可以以极少的代码和有限的带宽，为远程设备提供实时可靠的消息服务。做为一种低开销、低带宽占用的即时通讯协议，MQTT在物联网、小型设备、移动应用等方面有广泛的应用。</p>
<p>当然，在物联网开发中，MQTT不是唯一的选择，与MQTT互相竞争的协议有XMPP和CoAP协议等，文章末尾会有一个比较和说明。</p>
<h1 id="mqtt是哪一层协议">MQTT是哪一层协议？</h1>
<p>众所周知，TCP/IP参考模型可以分为四层：应用层、传输层、网络层、链路层。TCP和UDP位于传输层，应用层常见的协议有HTTP、FTP、SSH等。MQTT协议运行于TCP之上，属于应用层协议，因此只要是支持TCP/IP协议栈的地方，都可以使用MQTT。</p>
<h1 id="mqtt消息格式">MQTT消息格式</h1>
<p>每条MQTT命令消息的消息头都包含一个固定的报头，有些消息会携带一个可变报文头和一个负荷。消息格式如下：</p>
<p>固定报文头 | 可变报文头 | 负荷</p>
<h2 id="固定报文头fixed-header">固定报文头（Fixed Header）</h2>
<p>MQTT固定报文头最少有两个字节，第一字节包含消息类型（Message Type）和QoS级别等标志位。第二字节开始是剩余长度字段，该长度是后面的可变报文头加消息负载的总长度，该字段最多允许四个字节。</p>
<p>剩余长度字段单个字节最大值为二进制0b0111 1111，16进制0x7F。也就是说，单个字节可以描述的最大长度是127字节。为什么不是256字节呢？因为MQTT协议规定，单个字节第八位（最高位）若为1，则表示后续还有字节存在，第八位起“延续位”的作用。</p>
<p>例如，数字64，编码为一个字节，十进制表示为64，十六进制表示为0×40。数字321（65+2*128）编码为两个字节，重要性最低的放在前面，第一个字节为65+128=193（0xC1），第二个字节是2（0x02），表示2×128。</p>
<p>由于MQTT协议最多只允许使用四个字节表示剩余长度（如表1），并且最后一字节最大值只能是0x7F不能是0xFF，所以能发送的最大消息长度是256MB，而不是512MB。</p>
<h2 id="可变报文头variable-header">可变报文头（Variable Header）</h2>
<p>可变报文头主要包含协议名、协议版本、连接标志（Connect Flags）、心跳间隔时间（Keep Alive timer）、连接返回码（Connect Return Code）、主题名（Topic Name）等，后面会针对主要部分进行讲解。</p>
<h2 id="有效负荷payload">有效负荷（Payload）</h2>
<p>Payload直译为负荷，可能让人摸不着头脑，实际上可以理解为消息主体（body）。</p>
<p>当MQTT发送的消息类型是CONNECT（连接）、PUBLISH（发布）、SUBSCRIBE（订阅）、SUBACK（订阅确认）、UNSUBSCRIBE（取消订阅）时，则会带有负荷。</p>
<h1 id="mqtt的主要特性">MQTT的主要特性</h1>
<p>固定报文头中的第一个字节包含连接标志（Connect Flags），连接标志用来区分MQTT的消息类型。MQTT协议拥有14种不同的消息类型（如表2），可简单分为连接及终止、发布和订阅、QoS 2消息的机制以及各种确认ACK。至于每一个消息类型会携带什么内容，这里不多阐述。<br>
<img src="https://img-blog.csdn.net/20170725100930389" alt="" loading="lazy"></p>
<h1 id="消息质量qos">消息质量（Qos）</h1>
<p>MQTT消息质量有三个等级，QoS 0，QoS 1和 QoS 2。</p>
<p>QoS 0：最多分发一次。消息的传递完全依赖底层的TCP/IP网络，协议里没有定义应答和重试，消息要么只会到达服务端一次，要么根本没有到达。<br>
QoS 1：至少分发一次。服务器的消息接收由PUBACK消息进行确认，如果通信链路或发送设备异常，或者指定时间内没有收到确认消息，发送端会重发这条在消息头中设置了DUP位的消息。<br>
QoS 2：只分发一次。这是最高级别的消息传递，消息丢失和重复都是不可接受的，使用这个服务质量等级会有额外的开销。 <br>
通过下面的例子可以更深刻的理解上面三个传输质量等级。<br>
比如目前流行的共享单车智能锁，智能锁可以定时使用QoS level 0质量消息请求服务器，发送单车的当前位置，如果服务器没收到也没关系，反正过一段时间又会再发送一次。之后用户可以通过App查询周围单车位置，找到单车后需要进行解锁，这时候可以使用QoS level 1质量消息，手机App不断的发送解锁消息给单车锁，确保有一次消息能达到以解锁单车。最后用户用完单车后，需要提交付款表单，可以使用QoS level 2质量消息，这样确保只传递一次数据，否则用户就会多付钱了。</p>
<h1 id="遗愿标志-will-flag">遗愿标志 （Will Flag）</h1>
<p>在可变报文头的连接标志位字段（Connect Flags）里有三个Will标志位：Will Flag、Will QoS和Will Retain Flag，这些Will字段用于监控客户端与服务器之间的连接状况。如果设置了Will Flag，就必须设置Will QoS和Will Retain标志位，消息主体中也必须有Will Topic和Will Message字段。</p>
<p>那遗愿消息是怎么回事呢？服务器与客户端通信时，当遇到异常或客户端心跳超时的情况，MQTT服务器会替客户端发布一个Will消息。当然如果服务器收到来自客户端的DISCONNECT消息，则不会触发Will消息的发送。 <br>
因此，Will字段可以应用于设备掉线后需要通知用户的场景。</p>
<h1 id="连接保活心跳机制keep-alive-timer">连接保活心跳机制（Keep Alive Timer）</h1>
<p>MQTT客户端可以设置一个心跳间隔时间（Keep Alive Timer），表示在每个心跳间隔时间内发送一条消息。如果在这个时间周期内，没有业务数据相关的消息，客户端会发一个PINGREQ消息，相应的，服务器会返回一个PINGRESP消息进行确认。如果服务器在一个半（1.5）心跳间隔时间周期内没有收到来自客户端的消息，就会断开与客户端的连接。心跳间隔时间最大值大约可以设置为18个小时，0值意味着客户端不断开。</p>
<h1 id="mqtt其他特点">MQTT其他特点</h1>
<h2 id="异步发布-订阅实现">异步发布、订阅实现</h2>
<p>发布/订阅模式解耦了发布消息的客户（发布者）与订阅消息的客户（订阅者）之间的关系，这意味着发布者和订阅者之间并不需要直接建立联系。<br>
这个模式有以下好处：</p>
<p>发布者与订阅者只需要知道同一个消息代理即可；<br>
发布者和订阅者不需要直接交互；<br>
发布者和订阅者不需要同时在线。<br>
由于采用了发布/订阅实现，MQTT可以双向通信。也就是说MQTT支持服务端反向控制设备，设备可以订阅某个主题，然后发布者对该主题发布消息，设备收到消息后即可进行一系列操作。</p>
<h2 id="二进制格式实现">二进制格式实现</h2>
<p>MQTT基于二进制实现而不是字符串，比如HTTP和XMPP都是基于字符串实现。由于HTTP和XMPP拥有冗长的协议头部，而MQTT固定报文头仅有两字节，所以相比其他协议，发送一条消息最省流量。</p>
<h2 id="mqtt的安全">MQTT的安全</h2>
<p>由于MQTT运行于TCP层之上并以明文方式传输，这就相当于HTTP的明文传输，使用Wireshark可以完全看到MQTT发送的所有消息，消息指令一览无遗<br>
!()[https://img-blog.csdn.net/20170725101215295]</p>
<p>这样可能会产生以下风险：</p>
<p>设备可能会被盗用；<br>
客户端和服务端的静态数据可能是可访问的（可能会被修改）；<br>
协议行为可能有副作用（如计时器攻击）；<br>
拒绝服务攻击；<br>
通信可能会被拦截、修改、重定向或者泄露；<br>
虚假控制报文注入。<br>
作为传输协议，MQTT仅关注消息传输，提供合适的安全功能是开发者的责任。安全功能可以从三个层次来考虑——应用层、传输层、网络层。</p>
<p>应用层：在应用层上，MQTT提供了客户标识（Client Identifier）以及用户名和密码，可以在应用层验证设备。<br>
传输层：类似于HTTPS，MQTT基于TCP连接，也可以加上一层TLS，传输层使用TLS加密是确保安全的一个好手段，可以防止中间人攻击。客户端证书不但可以作为设备的身份凭证，还可以用来验证设备。<br>
网络层：如果有条件的话，可以通过拉专线或者使用VPN来连接设备与MQTT代理，以提高网络传输的安全性。</p>
<h1 id="总结">总结</h1>
<p>MQTT基于异步发布/订阅的实现解耦了消息发布者和订阅者，基于二进制的实现节省了存储空间及流量，同时MQTT拥有更好的消息处理机制，可以替代TCP Socket一部分应用场景。相对于HTTP和XMPP，MQTT可以选择用户数据格式，解析复杂度低，同时MQTT也可用于手机推送等领域。手机作为与人连接的入口，正好建立了人与物的连接，可谓一箭双雕。当然，其他协议也可以作为一个辅助的存在，HTTP可以为只需定时上传数据的设备服务，CoAP则更适用于非常受限的移动通信网络。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[美图长连接平台]]></title>
        <id>https://miexxx.github.io/post/mei-tu-chang-lian-jie-ping-tai/</id>
        <link href="https://miexxx.github.io/post/mei-tu-chang-lian-jie-ping-tai/">
        </link>
        <updated>2020-05-25T07:03:31.000Z</updated>
        <content type="html"><![CDATA[<h1 id="美图长连接服务">美图长连接服务</h1>
<p>随着科技的飞速发展，技术的日新月异，长连接的运用场景日益增多。不仅在后端服务中被广泛运用，比较常见的有数据库的访问、服务内部状态的协调等，而且在 App  端的消息推送、聊天信息、直播弹字幕等场景长连接服务也是优选方案。长连接服务的重要性也在各个场合被业界专家不断提及，与此同时也引起了更为广泛地关注和讨论，各大公司也开始构建自己的长连接服务。</p>
<p>美图公司于2016 年初开始构建长连接服务，与此同时， Go 在编程语言领域异军突起，考虑到其丰富的编程库，完善的工具链，简单高效的并发模型等优势，使我们最终选择 Go 去作为实现长连接服务的语言。在通信协议的选择上，考虑到 MQTT 协议的轻量、简单、易于实现的优点，选择了 MQTT 协议作为数据交互的载体。其整体的架构会在下文中做相应地介绍。</p>
<p>美图长连接服务（项目内部代号为bifrost ）已经历时三年，在这三年的时间里，长连接服务经过了业务的检验，同时也经历了服务的重构，存储的升级等，长连接服务从之前支持单机二十几万连接到目前可以支撑单机百万连接。在大多数长连接服务中存在一个共性问题，那就是内存占用过高，我们经常发现单个节点几十万的长连接，内存却占用十几G 甚至更多，有哪些手段能降低内存呢？</p>
<p>本文将从多个角度介绍长连接服务在内存优化路上的探索，首先会先通过介绍当前服务的架构模型，Go 语言的内存管理，让大家清晰地了解我们内存优化的方向和关注的重要数据。后面会重点介绍我们在内存优化上做的一些尝试以及具体的优化手段，希望对大家有一定的借鉴意义。</p>
<h1 id="架构模型">架构模型</h1>
<p><img src="https://mlog.club/api/img/proxy?url=https%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_png%2F8XkvNnTiapON5Uia1wzpCd7y4KId7K77ElzicUjqlKZPG0TcpdY0pvwQMcWwT7ok24ALKYwibKJz7ekkuOib7a6ibxSw%2F640%3Fwx_fmt%3Dpng" alt="" loading="lazy"><br>
从架构图中我们可以清晰地看到由7 个模块组成，分别是：conf 、grpcsrv 、mqttsrv、session、pubsub、packet、util ，每个模块的作用如下：</p>
<p>conf ：配置管理中心，负责服务配置的初始化，基本字段校验。</p>
<p>grpcsrv ：grpc 服务，集群内部信息交互协调。</p>
<p>mqttsrv ：mqtt 服务，接收客户端连接，同时支持单进程多端口 MQTT 服务。</p>
<p>session ：会话模块，管理客户端状态变化，MQTT 信息的收发。</p>
<p>pubsub ：发布订阅模块，按照 Topic 维度保存 session 并发布 Topic 通知给 session。</p>
<p>packet：协议解析模块，负责 MQTT 协议包解析。</p>
<p>util ：工具包，目前集成监控、日志、grpc 客户端、调度上报四个子模块。</p>
<h1 id="go的内存管理">Go的内存管理</h1>
<p>...</p>
<h1 id="业务优化">业务优化</h1>
<p>session模块主要用户处理消息的收发，在实现时考虑到在通常场景中业务的消息生产大于客户端的消费速度的情况，为了缓解这种状况，设计时引入消息的缓冲队列，这种做法同样也有助于做客户端消息的流控。</p>
<p>缓冲消息队列借助chan 实现 ，chan 大小根据经验将初始化默认配置为 128 。但在目前线上推送的场景中，我们发现，消息的生产一般小于消费的速度，128 缓冲大小明显偏大，因此我们把长度调整为 16 ，减少内存的分配。</p>
<p>在设计中按照topic 对客户端进行分组管理的算法中，采用空间换时间的方式，组合 map 和 list 两种数据结构对于客户端集合操作提供O（1）的删除、O（1）的添加、O（n）的遍历。数据的删除采用标记删除方式，使用辅助 slice 结构进行记录，只有到达预设阈值才会进行真正的删除。虽然标记删除提高了遍历和添加的性能，但也同样带来了内存损耗问题。</p>
<p>大家一定好奇什么样的场景需要提供这样的复杂度，在实际中其场景有以下两种情况：</p>
<p>在实际的网络场景中，客户端随时都可能由于网络的不稳定断开或者重新建联，因此集合的增加和删除需要在常数范围内。</p>
<p>在消息发布的流程中，采用遍历集合逐一发布通知方式，但随着单个topic 上的用户量的增加，经常会出现单个 topic 用户集合消息过热的问题，耗时太久导致消息挤压，因此针对集合的遍历当然也要求尽量快。</p>
<p>通过benchamrk 数据分析，在标记回收 slice 长度在 1000 时，可以提供最佳的性能，因此默认配置阈值为 1000。在线上服务中，无特殊情况都是采用默认配置。但在当前推送服务的使用中，发现标记删除和延迟回收机制好处甚微，主要是因为 topic 和客户端为 1 : 1 方式，也就是不存在客户端集合，因此调整回收阈值大小为 2，减少无效内存占用。</p>
<p>上述所有优化，只要简单调整配置后服务灰度上线即可，在设计实现时通过conf 模块动态配置，降低了服务的开发和维护成本。通过监控对比优化效果如下表，在优化后在线连接数比优化的在线连接更多的情况下， heap 使用内存使用数量由原来的 4.16G 下降到了 3.5G ，降低了约 0.66 G。<br>
<img src="https://mlog.club/api/img/proxy?url=https%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_png%2F8XkvNnTiapON5Uia1wzpCd7y4KId7K77ElfUasn5axY8xkhabmqwefAa8onSBfkVGHNHJc9DbBo26n0zxibFCk7LA%2F640%3Fwx_fmt%3Dpng" alt="" loading="lazy"></p>
<h1 id="golang-代码优化">golang 代码优化</h1>
<p>在实现上面展示的架构的时候发现在session 模块 和 mqttsrv 模块之间存在很多共享变量，目前实现方式都是采用指针或者值拷贝的，由于 session的数量和客户端数据量成正比也就导致消耗大量内存用于共享数据，这不仅仅增加 GC 压力，同样对于内存的消耗也是巨大的。就此问题思考再三，参考系统的库 context 的设计在架构中也抽象 context 包负责模块之间交互信息传递，统一分配内存。此外还参考他人减少临时变量的分配的优化方式，提高系统运行效率。主要优化角度参考如下：</p>
<p>在频繁申请内存的地方，使用pool 方式进行内存管理</p>
<p>小对象合并成结构体一次分配，减少内存分配次数</p>
<p>缓存区内容一次分配足够大小空间，并适当复用</p>
<p>slice 和 map 采 make 创建时，预估大小指定容量</p>
<p>调用栈避免申请较多的临时对象</p>
<p>减少[]byte 与 string 之间转换，尽量采用 []byte 来字符串处理</p>
<p>目前系统具被完备的单元测试、集成测试，因此经过一周的快速的开发重构后灰度上线监控数据对比如下表：在基本相同的连接数上，heap 使用内存约占用降低 0.27G，stack 申请内存占用降低 3.81G。为什么 stack 会大幅度降低呢？</p>
<p>通过设置stackDebug 重新编译程序追查程序运行过程，优化前 goroutine 栈的大多数在内存为 16K，通过减少临时变量的分配，拆分大函数处理逻辑，有效的减少触发栈的内存扩容（详细分析见参考文章），优化后 goroutine 栈内存降低到 8 K。一个连接需要启动两个 goroutine 负责数据的读和写，粗略计算一个连接减少约 16 K 的内存，23 w 连接约降低 3.68 G 内存。<br>
<img src="https://mlog.club/api/img/proxy?url=https%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_png%2F8XkvNnTiapON5Uia1wzpCd7y4KId7K77ElCJia4XkicRiclW1ChszUFWUu2Lzf8LrMUuDb6iajILtLuMD6JfS5wzUiaNA%2F640%3Fwx_fmt%3Dpng" alt="" loading="lazy"></p>
<h1 id="网络模型优化">网络模型优化</h1>
<p>在Go 语言的网络编程中经典的实现都是采用同步处理方式，启动两个 goroutine 分别处理读和写请求，goroutine 也不像 thread ，它是轻量级的。但对于一百万连接的情况，这种设计模式至少要启动两百万的 goroutine，其中一个 goroutine 使用栈的大小在 2 KB 到 8KB， 对于资源的消耗也是极大的。在大多数场景中，只有少数连接是有数据处理，大部分 goroutine 阻塞 IO 处理中。在因此可以借鉴 C 语言的设计，在程序中使用 epoll 模型做事件分发，只有活跃连接才会启动 goroutine 处理业务，基于这种思想修改网络处理流程。</p>
<p>网络模型修改测试完成后开始灰度上线，通过监控数据对比如下表：在优化后比优化前的连接数多10 K的情况下，heap 使用内存降低 0.33 G，stack 申请内存降低 2.34 G，优化效果显著。</p>
<figure data-type="image" tabindex="1"><img src="https://mlog.club/api/img/proxy?url=https%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_png%2F8XkvNnTiapON5Uia1wzpCd7y4KId7K77ElIzPXia18GePGJpqGOH21piaHDYhvb9vYPwiaSrW9MQCvdkxAKL0UvC7fQ%2F640%3Fwx_fmt%3Dpng" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Swoole：Master/Reactor/Manager/Worker/TaskWorker(Task)]]></title>
        <id>https://miexxx.github.io/post/swoolemasterreactormanagerworkertaskworkertask/</id>
        <link href="https://miexxx.github.io/post/swoolemasterreactormanagerworkertaskworkertask/">
        </link>
        <updated>2020-05-22T05:46:16.000Z</updated>
        <content type="html"><![CDATA[<h1 id="swoolemasterreactormanagerworkertaskworkertask">Swoole：Master/Reactor/Manager/Worker/TaskWorker(Task)</h1>
<figure data-type="image" tabindex="1"><img src="https://ss1.baidu.com/6ONXsjip0QIZ8tyhnq/it/u=4118852065,2174358700&amp;fm=173&amp;app=49&amp;f=JPEG?w=640&amp;h=329&amp;s=78E1B544CFBA0409589B83650300F053" alt="" loading="lazy"></figure>
<h2 id="master进程">Master进程</h2>
<p>master进程为主进程,该进程会创建Manager进程和Reactor线程等工作进/线程<br>
swoole的主进程,是个多线程的程序.</p>
<h3 id="主进程内的回调函数">主进程内的回调函数：</h3>
<p>onStart<br>
onShutdown<br>
onMasterConnect<br>
onMasterClose<br>
onTimer<br>
...</p>
<h2 id="reactor线程">Reactor线程</h2>
<p>Reactor线程是真正处理TCP连接，收发数据的线程。<br>
Swoole的主线程在Accept新的连接后，会将这个连接分配给一个固定的Reactor线程，并由这个线程负责监听此socket。在socket可读时读取数据，并进行协议解析，将请求投递到Worker进程。在socket可写时将数据发送给TCP客户端.</p>
<h2 id="manager进程">Manager进程</h2>
<p>Manager进程是管理进程,该进程是为了创建管理所有的woker进程和TaskWorker进程,swoole中worker/task进程都是由Manager进程Fork并管理的。(master主进程为多线程进程,不能安全的执行fork操作)</p>
<p>子进程结束运行时，manager进程负责回收此子进程，避免成为僵尸进程。并创建新的子进程<br>
服务器关闭时，manager进程将发送信号给所有子进程，通知子进程关闭服务<br>
服务器reload时，manager进程会逐个关闭/重启子进程</p>
<h3 id="管理进程内的回调函数">管理进程内的回调函数</h3>
<p>onManagerStart<br>
onManagerStop</p>
<h2 id="worker进程">Worker进程</h2>
<p>worker进程是工作进程,所有的业务逻辑都在该进程中进行,当Reactor线程接收到来自客户端的数据后，会将数据打包通过管道发送给某个Worker进程.</p>
<p>Swoole提供了完善的进程管理机制，当Worker进程异常退出，如发生PHP的致命错误、被其他程序误杀，或达到max_request次数之后正常退出。主进程会重新拉起新的Worker进程。 Worker进程内可以像普通的apache+php或者php-fpm中写代码。不需要像Node.js那样写异步回调的代码。</p>
<h3 id="worker进程内的回调函数">Worker进程内的回调函数</h3>
<p>onWorkerStart<br>
onWorkerStop<br>
onConnect<br>
onClose<br>
onReceive<br>
onTimer<br>
onFinish</p>
<h2 id="taskworker进程">TaskWorker进程</h2>
<p>Swoole的业务逻辑部分是同步阻塞运行的，如果遇到一些耗时较大的操作，例如访问数据库、广播消息等，就会影响服务器的响应速度。因此Swoole提供了Task功能，将这些耗时操作放到另外的进程去处理，当前进程继续执行后面的逻辑</p>
<p>task进程必须是同步阻塞的,task进程支持定时器</p>
<h3 id="taskworker进程内的回调函数">TaskWorker进程内的回调函数</h3>
<p>onTask<br>
onWorkerStart</p>
<h2 id="职责功能">职责功能</h2>
<h3 id="reactor线程-2">Reactor线程</h3>
<p>负责维护客户端TCP连接、处理网络IO、处理协议、收发数据<br>
完全是异步非阻塞的模式<br>
全部为C代码，除Start/Shudown事件回调外，不执行任何PHP代码将<br>
TCP客户端发来的数据缓冲、拼接、拆分成完整的一个请求数据包<br>
Reactor以多线程的方式运行</p>
<h3 id="worker进程-2">Worker进程</h3>
<p>接受由Reactor线程投递的请求数据包，并执行PHP回调函数处理数据生成响应数据并发给<br>
Reactor线程，由Reactor线程发送给TCP客户端<br>
可以是异步非阻塞模式，也可以是同步阻塞模式<br>
Worker以多进程的方式运行</p>
<h3 id="taskworker进程-2">TaskWorker进程</h3>
<p>接受由Worker进程通过swoole_server-&gt;task/taskwait方法投递的任务<br>
处理任务，并将结果数据返回(swoole_server-&gt;finish)给Worker进程<br>
完全是同步阻塞模式<br>
TaskWorker以多进程的方式运行</p>
<h3 id="关系">关系</h3>
<p>可以理解为Reactor就是nginx，Worker就是php-fpm。Reactor线程异步并行地处理网络请求，然后再转发给Worker进程中去处理。Reactor和Worker间通过UnixSocket进行通信。在php-fpm的应用中，经常会将一个任务异步投递到Redis等队列中，并在后台启动一些php进程异步地处理这些任务。Swoole提供的TaskWorker是一套更完整的方案，将任务的投递、队列、php任务处理进程管理合为一体。通过底层提供的API可以非常简单地实现异步任务的处理。另外TaskWorker还可以在任务执行完成后，再返回一个结果反馈到Worker。Swoole的Reactor、Worker、TaskWorker之间可以紧密的结合起来，提供更高级的使用方式。一个更通俗的比喻，假设Server就是一个工厂，那Reactor就是销售，接受客户订单。而Worker就是工人，当销售接到订单后，Worker去工作生产出客户要的东西。而TaskWorker可以理解为行政人员，可以帮助Worker干些杂事，让Worker专心工作。</p>
<p>底层会为Worker进程、TaskWorker进程分配一个唯一的ID不同的Worker和TaskWorker进程之间可以通过sendMessage接口进行通信</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Zookeeper集群 + canal服务 搭建]]></title>
        <id>https://miexxx.github.io/post/zookeeper-ji-qun-da-jian/</id>
        <link href="https://miexxx.github.io/post/zookeeper-ji-qun-da-jian/">
        </link>
        <updated>2020-04-28T11:40:18.000Z</updated>
        <content type="html"><![CDATA[<p></p>
<h1 id="zookeeper简介">zookeeper简介</h1>
<p>顾名思义 zookeeper 就是动物园管理员，他是用来管 hadoop（大象）、Hive(蜜蜂)、pig(小 猪)的管理员， Apache Hbase 和 Apache Solr 的分布式集群都用到了 zookeeper；Zookeeper: 是一个分布式的、开源的程序协调服务，是 hadoop 项目下的一个子项目。他提供的主要功 能包括：配置管理、名字服务、分布式锁、集群管理</p>
<h1 id="zookeeper作用">zookeeper作用</h1>
<h2 id="公共配置管理">公共配置管理</h2>
<h2 id="服务器共用hosts名字服务">服务器共用hosts，名字服务</h2>
<h2 id="分布式锁">分布式锁</h2>
<h2 id="集群管理竞选策略">集群管理，竞选策略</h2>
<p>本文章，主要讲解搭建内容，理论方面不再阐述。</p>
<h1 id="单机多节点搭建要点">单机多节点搭建要点</h1>
<p>需要修改每个节点存储日志目录（/usr/local/var/run/zookeeper/data/zoo-1/），每个节点需要创建myid。</p>
<p>创建多个节点copy多分zoo.cfg文件，修改配置内容，主要配置其他节点的地址，与客户端端口。</p>
<pre><code>clientPort=2182
server.1=127.0.0.1:2666:3666
server.2=127.0.0.1:2667:3667
server.3=127.0.0.1:2668:3668
</code></pre>
<p>每个节点依次启动<br>
服务端：zkServer  start zoo-1.cfg</p>
<p>客户端可连接任意端口：zkCli -server ip:port(客户端端口)</p>
<h1 id="canal简介">canal简介</h1>
<p>canal是阿里巴巴开源的mysql数据库binlog的增量订阅&amp;消费组件。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Http]]></title>
        <id>https://miexxx.github.io/post/http/</id>
        <link href="https://miexxx.github.io/post/http/">
        </link>
        <updated>2020-04-28T06:49:12.000Z</updated>
        <content type="html"><![CDATA[<h1 id="基础概念">基础概念</h1>
<h2 id="uri">uri</h2>
<p>uri包好url 和urn<br>
<img src="https://camo.githubusercontent.com/b61eb498c8b9458916441d9341d3975b6e1134cf/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f38343431623263342d646361372d346436622d386566622d6632326566636361663333312e706e67" alt="" loading="lazy"></p>
<h2 id="请求和响应报文">请求和响应报文</h2>
<h3 id="请求报文">请求报文</h3>
<figure data-type="image" tabindex="1"><img src="https://camo.githubusercontent.com/f48540e5efe054841d1aa19097666c4b35500c10/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f485454505f526571756573744d6573736167654578616d706c652e706e67" alt="" loading="lazy"></figure>
<h3 id="响应报文">响应报文</h3>
<figure data-type="image" tabindex="2"><img src="https://camo.githubusercontent.com/6ee5dc048dd39a9c4f9a180cee34c66b196a7c45/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f485454505f526573706f6e73654d6573736167654578616d706c652e706e67" alt="" loading="lazy"></figure>
<h3 id="get">GET</h3>
<p>获取资源<br>
当前网络请求中，绝大部分使用的是GET方法。</p>
<h3 id="head">HEAD</h3>
<p>获取报文首部<br>
和GET方法类似，但是不返回报文实体主体部分。<br>
主要用于确认URL的有效性以及资源更新的日期时间等。</p>
<h3 id="post">POST</h3>
<p>传输实体主体<br>
POST主要用来传输数据，而GET主要用来获取资源。</p>
<h3 id="put">PUT</h3>
<p>上传文件<br>
由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。</p>
<h3 id="patch">PATCH</h3>
<p>对资源进行部分修改<br>
PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。</p>
<h3 id="delete">DELETE</h3>
<p>删除文件<br>
与PUT功能相反，并且同样不带验证机制。</p>
<h3 id="options">OPTIONS</h3>
<p>查询支持的方法<br>
查询指定URL能够支持的方法</p>
<h3 id="connect">CONNECT</h3>
<p>要求在与代理服务器通信时简历隧道<br>
使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。<br>
CONNECT www.example.com:443 HTTP/1.1</p>
<h3 id="trace">TRACE</h3>
<p>服务器会将通信路径返回给客户端。<br>
发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。<br>
通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。</p>
<h2 id="http状态码">HTTP状态码</h2>
<p>服务器返回的 响应报文 中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。</p>
<h3 id="1xx信息">1xx信息</h3>
<p>100 Continue:表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。</p>
<h3 id="2xx成功">2xx成功</h3>
<p>200 ok<br>
204 No Content :请求已经成功处理，但是响应报文不包含实体的主题部分。<br>
一般只需要从客户端往服务器发送信息，而不逊要返回数据时使用。<br>
206 Partial Content：表示客户端进行了范围请求，响应报文报文包含 Content-Range 指定范围的实体内容。</p>
<h3 id="3xx重定向">3xx重定向</h3>
<p>301 Moved Permanmently : 永久重定向<br>
302 Found : 临时性重定向<br>
303 See Other： 和302有着相同的功能，但是303明确客户端应该采用GET方法获取资源<br>
304 Not Modified: 如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。<br>
307 Temporary Redirect: 临时重定向, 与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。</p>
<h3 id="4xx-客户端错误">4xx 客户端错误</h3>
<p>400 Bad Request ：请求报文中存在语法错误。<br>
401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。<br>
403 Forbidden ：请求被拒绝。<br>
404 Not Found</p>
<h3 id="5xx-服务端错误">5xx 服务端错误</h3>
<p>500 Internal Server Error ：服务器正在执行请求时发生错误。</p>
<p>503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。</p>
<h2 id="http首部">HTTP首部</h2>
<h3 id="实体首部">实体首部</h3>
<h3 id="请求首部">请求首部</h3>
<h3 id="响应首部">响应首部</h3>
<h2 id="具体应用">具体应用</h2>
<h3 id="连接管理">连接管理</h3>
<h4 id="短连接与长连接">短连接与长连接</h4>
<p>当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问的 HTML 页面资源，还会请求图片资源。如果每进行一次 HTTP 通信就要新建一个 TCP 连接，那么开销会很大。</p>
<p>长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。</p>
<p>从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close；<br>
在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive。</p>
<h4 id="流水线">流水线</h4>
<p>默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。<br>
流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。</p>
<h4 id="cookie">cookie</h4>
<p>HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。</p>
<p>Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。</p>
<p>Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。</p>
<h5 id="用途">用途</h5>
<p>会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）<br>
个性化设置（如用户自定义设置、主题等）<br>
浏览器行为跟踪（如跟踪分析用户行为等）</p>
<h5 id="创建过程">创建过程</h5>
<p>服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。</p>
<p>HTTP/1.0 200 OK<br>
Content-type: text/html<br>
Set-Cookie: yummy_cookie=choco<br>
Set-Cookie: tasty_cookie=strawberry</p>
<p>[page content]<br>
客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。</p>
<p>GET /sample_page.html HTTP/1.1<br>
Host: www.example.org<br>
Cookie: yummy_cookie=choco; tasty_cookie=strawberry</p>
<h5 id="分类">分类</h5>
<p>会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。<br>
持久性 Cookie：指定过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie。<br>
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;</p>
<h5 id="作用域">作用域</h5>
<p>Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。</p>
<p>Path 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F (&quot;/&quot;) 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配：</p>
<p>/docs<br>
/docs/Web/<br>
/docs/Web/HTTP</p>
<h5 id="javascript">JavaScript</h5>
<p>浏览器通过 document.cookie 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。</p>
<p>document.cookie = &quot;yummy_cookie=choco&quot;;<br>
document.cookie = &quot;tasty_cookie=strawberry&quot;;<br>
console.log(document.cookie);</p>
<h5 id="httponly">HttpOnly</h5>
<p>标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。</p>
<p>Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly</p>
<h5 id="secure">Secure</h5>
<p>标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。</p>
<h5 id="session">Session</h5>
<p>除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。</p>
<p>Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。</p>
<p>使用 Session 维护用户登录状态的过程如下：</p>
<p>用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；<br>
服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；<br>
服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；<br>
客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。<br>
应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。</p>
<h5 id="浏览器禁用cookie">浏览器禁用Cookie</h5>
<p>此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。</p>
<h5 id="cookie-与-session-选择">Cookie 与 Session 选择</h5>
<p>Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session；<br>
Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；<br>
对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。</p>
<h2 id="缓存">缓存</h2>
<h3 id="优点">优点</h3>
<p>缓解服务器压力；<br>
降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。</p>
<h3 id="实现方法">实现方法</h3>
<p>让代理服务器进行缓存；<br>
让客户端浏览器进行缓存。</p>
<h3 id="cache-control">Cache-Control</h3>
<p>HTTP/1.1 通过 Cache-Control 首部字段来控制缓存。</p>
<h4 id="禁止进行缓存">禁止进行缓存</h4>
<p>no-store 指令规定不能对请求或响应的任何一部分进行缓存。<br>
Cache-Control: no-store</p>
<h4 id="强制确认缓存">强制确认缓存</h4>
<p>no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。</p>
<p>Cache-Control: no-cache</p>
<h4 id="私有缓存和公共缓存">私有缓存和公共缓存</h4>
<p>private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。</p>
<p>Cache-Control: private<br>
public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中。</p>
<p>Cache-Control: public</p>
<h4 id="缓存过期机制">缓存过期机制</h4>
<p>max-age 指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。</p>
<p>max-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间。</p>
<p>Cache-Control: max-age=31536000<br>
Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。</p>
<p>Expires: Wed, 04 Jul 2012 08:26:05 GMT<br>
在 HTTP/1.1 中，会优先处理 max-age 指令；<br>
在 HTTP/1.0 中，max-age 指令会被忽略掉。</p>
<h4 id="缓存验真">缓存验真</h4>
<p>需要先了解 ETag 首部字段的含义，它是资源的唯一标识。URL 不能唯一表示资源，例如 http://www.google.com/ 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一标识。</p>
<p>ETag: &quot;82e22293907ce725faf67773957acd12&quot;<br>
可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。</p>
<p>If-None-Match: &quot;82e22293907ce725faf67773957acd12&quot;<br>
Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有实体主体的 304 Not Modified 响应报文。</p>
<p>Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT<br>
If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT</p>
<h2 id="内部协商">内部协商</h2>
<p>通过内容协商返回最合适的内容，例如根据浏览器的默认语言选择返回中文界面还是英文界面。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Crontab]]></title>
        <id>https://miexxx.github.io/post/cr/</id>
        <link href="https://miexxx.github.io/post/cr/">
        </link>
        <updated>2020-04-23T12:36:57.000Z</updated>
        <content type="html"><![CDATA[<h2 id="问题">问题：</h2>
<p>crontab设置定时任务时，* * * * * php 1.php， 找不到php环境变量，导致任务执行失败。</p>
<p>解决方法：输入完整php路径。 * * * * * /usr/local/php 1.php</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux]]></title>
        <id>https://miexxx.github.io/post/linux/</id>
        <link href="https://miexxx.github.io/post/linux/">
        </link>
        <updated>2020-04-07T12:59:48.000Z</updated>
        <content type="html"><![CDATA[<h2 id="sync">sync</h2>
<p>为了加快对磁盘文件的读写速度，位于内存中的文件数据不会立即同步到磁盘，因此关机之前需要先进行 sync 同步操作。</p>
<h2 id="path">PATH</h2>
<p>可以在环境变量 PATH 中声明可执行文件的路径，路径之间用 : 分隔。</p>
<pre><code>/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/dmtsai/.local/bin:/home/dmtsai/bin
</code></pre>
<h2 id="磁盘的文件名">磁盘的文件名</h2>
<p>Linux 中每个硬件都被当做一个文件，包括磁盘。磁盘以磁盘接口类型进行命名，常见磁盘的文件名如下：<br>
IDE 磁盘：/dev/hd[a-d]<br>
SATA/SCSI/SAS 磁盘：/dev/sd[a-p]<br>
其中文件名后面的序号的确定与系统检测到磁盘的顺序有关，而与磁盘所插入的插槽位置无关。</p>
<h2 id="分区">分区</h2>
<p>磁盘分区表主要有两种格式，一种是限制较多的 MBR 分区表，一种是较新且限制较少的 GPT 分区表。</p>
<h3 id="mbr">MBR</h3>
<p>MBR 中，第一个扇区最重要，里面有主要开机记录（Master boot record, MBR）及分区表（partition table），其中主要开机记录占 446 bytes，分区表占 64 bytes。<br>
分区表只有 64 bytes，最多只能存储 4 个分区，这 4 个分区为主分区（Primary）和扩展分区（Extended）。其中扩展分区只有一个，它使用其它扇区来记录额外的分区表，因此通过扩展分区可以分出更多分区，这些分区称为逻辑分区。<br>
Linux 也把分区当成文件，分区文件的命名方式为：磁盘文件名 + 编号，例如 /dev/sda1。注意，逻辑分区的编号从 5 开始。</p>
<h2 id="文件系统">文件系统</h2>
<h3 id="分区与文件系统">分区与文件系统</h3>
<p>对分区进行格式化是为了在分区上建立文件系统，一个分区通常只能格式化为一个文件系统，但是磁盘阵列等技术可以将一个分区格式化为多个文件系统。</p>
<h3 id="组成">组成</h3>
<p>最主要的几个组成部分如下：<br>
innode:一个文件占用一个inode,记录文件的属性，同时记录此文件的内容所在block编号。<br>
block：记录文件内容，文件太大时，会占用多个block.<br>
除此之外还包括<br>
superblock:记录文件系统的整体信息，包括inode和block的总量，剩余量，使用量，以及文件系统的格式与相关信息等；<br>
block bitmap：记录block是否被使用的位图。<br>
<img src="https://camo.githubusercontent.com/af36cfca3a3122a49b13b40ec7ec4e54bf15b4c6/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f4253445f6469736b2e706e67" alt="" loading="lazy"></p>
<h3 id="文件读取">文件读取</h3>
<p>对于EXT2文件系统，当要读取一个文件的内容时，先在inode中查找文件内容所在的所有block,然后把所有的内容读出来。<br>
<img src="https://camo.githubusercontent.com/d81f8e4f37dc78a5f804a1dbe51c57a26685107f/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f31326136356363362d323065302d343730362d396665362d3362613439343133643766362e706e67" alt="" loading="lazy"></p>
<p>而对于FAT文件系统，它没有inode,每个block中存储着下一个block的编号。<br>
<img src="https://camo.githubusercontent.com/9e96d72b5464a3db0c8026716079bc44c9cf462a/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35623731386538362d373130322d346262362d386361352d6431646437393135333063352e706e67" alt="" loading="lazy"></p>
<h3 id="磁盘碎片">磁盘碎片</h3>
<p>☞一个文件内容所在的block过于分散，导致磁盘磁头移动距离过大，从而降低磁盘的读写性能。</p>
<h3 id="block">block</h3>
<p>在Ext2文件系统中所支持的block大小有1k，2k及4k三种，不同的大小限制了单个文件和文件系统的最大大小。<br>
一个block只能被一个文件所使用，未使用的部分直接浪费了。因此如果需要存储大量的小文件，那么最好选用比较小的block。</p>
<h3 id="inode">inode</h3>
<p>inode具体包含以下信息：<br>
权限、拥有者/群组、容量、建立或状态改变时间、最近读取时间、最近修改时间、定义文件特性的旗标、改文件真正内容的指向。</p>
<p>inode具有以下特点：<br>
每个inode大小均固定为128bytes (新的ext4 与 xfs可设定到256bytes)<br>
每个文件都仅会占用一个inode</p>
<p>inode 中记录了文件内容所在的 block 编号，但是每个 block 非常小，一个大文件随便都需要几十万的 block。而一个 inode 大小有限，无法直接引用这么多 block 编号。因此引入了间接、双间接、三间接引用。间接引用让 inode 记录的引用 block 块记录引用信息。</p>
<h3 id="目录">目录</h3>
<p>建立一个目录时，会分配一个inode与至少一个block，block记录的内容是目录下所有文件的inode编号以及文件名。<br>
可以看到文件的inode本身不记录文件名，文件名记录在目录中，因此新增文件，删除文件，更改文件名这些操作与目录的写权限有关。</p>
<h3 id="日志">日志</h3>
<p>如果突然断电，那么文件系统会发生错误，例如断电前只修改了block bitmap，而还没有将数据真正写入block中。ext3/ext4文件系统引入了日志功能，可以利用日志来修复文件系统。</p>
<h3 id="挂载">挂载</h3>
<p>挂载利用目录作为文件系统的进入点，也就是说，进入目录之后就可以读取文件系统的数据。</p>
<h3 id="目录配置">目录配置</h3>
<p>为了使不同linux发行版本的目录结构保持一致性，FHS规定了Linux的目录结构。最基础的三个目录如下：<br>
/root /usr /var<br>
<img src="https://camo.githubusercontent.com/b12257cb7875cb1263998e35d1826d5032484d25/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f6c696e75782d66696c6573797374656d2e706e67" alt="" loading="lazy"></p>
<h2 id="文件">文件</h2>
<h3 id="文件属性">文件属性</h3>
<p>用户分为三种：文件拥有者、群组以及其它人，对不同的用户有不同的文件权限。</p>
<p>使用 ls 查看一个文件时，会显示一个文件的信息，例如 drwxr-xr-x 3 root root 17 May 6 00:14 .config，对这个信息的解释如下：</p>
<p>drwxr-xr-x：文件类型以及权限，第 1 位为文件类型字段，后 9 位为文件权限字段<br>
3：链接数<br>
root：文件拥有者<br>
root：所属群组<br>
17：文件大小<br>
May 6 00:14：文件最后被修改的时间<br>
.config：文件名<br>
常见的文件类型及其含义有：</p>
<p>d：目录<br>
-：文件<br>
l：链接文件<br>
9 位的文件权限字段中，每 3 个为一组，共 3 组，每一组分别代表对文件拥有者、所属群组以及其它人的文件权限。一组权限中的 3 位分别为 r、w、x 权限，表示可读、可写、可执行。</p>
<p>文件时间有以下三种：</p>
<p>modification time (mtime)：文件的内容更新就会更新；<br>
status time (ctime)：文件的状态（权限、属性）更新就会更新；<br>
access time (atime)：读取文件时就会更新。</p>
<h3 id="文件与目录的基本操作">文件与目录的基本操作</h3>
<p>....</p>
<h3 id="链接">链接</h3>
<figure data-type="image" tabindex="1"><img src="https://camo.githubusercontent.com/160b6c73de6ad65d706650af3e95a7ae6f2be4d6/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f31653436666430332d306364612d346436302d396231632d3063323536656461663662322e706e67" alt="" loading="lazy"></figure>
<p>实体链接<br>
在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。<br>
删除任意一个条目，文件还是存在，只要引用数量不为 0。<br>
有以下限制：不能跨越文件系统、不能对目录进行链接。</p>
<p>ln /etc/crontab .<br>
ll -i /etc/crontab crontab<br>
34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 crontab<br>
34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab<br>
符号链接<br>
符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。</p>
<p>当源文件被删除了，链接文件就打不开了。</p>
<p>因为记录的是路径，所以可以为目录建立符号链接。</p>
<p>ll -i /etc/crontab /root/crontab2<br>
34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab<br>
53745909 lrwxrwxrwx. 1 root root 12 Jun 23 22:31 /root/crontab2 -&gt; /etc/crontab</p>
<h2 id="进程管理">进程管理</h2>
<h3 id="查看进程">查看进程：</h3>
<p>ps -l 查看自己的进程<br>
ps aux 查看系统所有进程<br>
ps aux | grep php 查看特定进程<br>
pstree -A 查看所有进程树<br>
top 实时显示进程信息<br>
top -d 2 两秒刷新一次<br>
netstat</p>
<h3 id="查看占用端口的进程">查看占用端口的进程</h3>
<p>netstat -anp | grep port</p>
<h3 id="进程状态">进程状态</h3>
<figure data-type="image" tabindex="2"><img src="https://camo.githubusercontent.com/18fd4fa4f90c39ea3024bc7e330940ed5761b201/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32626162343132372d336537642d343863632d393134652d3433366265383539666230352e706e67" alt="" loading="lazy"></figure>
<h3 id="sigchld">SIGCHLD</h3>
<p>当一个子进程改变了它的状态时（停止运行，继续运行或者退出），有两件事会发生在父进程中：</p>
<p>得到 SIGCHLD 信号；<br>
waitpid() 或者 wait() 调用会返回。<br>
其中子进程发送的 SIGCHLD 信号包含了子进程的信息，比如进程 ID、进程状态、进程使用 CPU 的时间等。</p>
<p>在子进程退出时，它的进程描述符不会立即释放，这是为了让父进程得到子进程信息，父进程通过 wait() 和 waitpid() 来获得一个已经退出的子进程的信息。</p>
<h3 id="wait">wait()</h3>
<p>父进程调用 wait() 会一直阻塞，直到收到一个子进程退出的 SIGCHLD 信号，之后 wait() 函数会销毁子进程并返回。</p>
<p>如果成功，返回被收集的子进程的进程 ID；如果调用进程没有子进程，调用就会失败，此时返回 -1，同时 errno 被置为 ECHILD。</p>
<p>参数 status 用来保存被收集的子进程退出时的一些状态，如果对这个子进程是如何死掉的毫不在意，只想把这个子进程消灭掉，可以设置这个参数为 NULL。</p>
<h3 id="waitpid">waitpid()</h3>
<p>作用和 wait() 完全相同，但是多了两个可由用户控制的参数 pid 和 options。</p>
<p>pid 参数指示一个子进程的 ID，表示只关心这个子进程退出的 SIGCHLD 信号。如果 pid=-1 时，那么和 wait() 作用相同，都是关心所有子进程退出的 SIGCHLD 信号。</p>
<p>options 参数主要有 WNOHANG 和 WUNTRACED 两个选项，WNOHANG 可以使 waitpid() 调用变成非阻塞的，也就是说它会立即返回，父进程可以继续执行其它任务。</p>
<h3 id="孤儿进程">孤儿进程</h3>
<p>一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。</p>
<p>孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。</p>
<p>由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。</p>
<h3 id="僵尸进程">僵尸进程</h3>
<p>一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。</p>
<p>僵尸进程通过 ps 命令显示出来的状态为 Z（zombie）。</p>
<p>系统所能使用的进程号是有限的，如果产生大量僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。</p>
<p>要消灭系统中大量的僵尸进程，只需要将其父进程杀死，此时僵尸进程就会变成孤儿进程，从而被 init 进程所收养，这样 init 进程就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程。</p>
<h2 id="系统诊断命令">系统诊断命令</h2>
<h3 id="free">free</h3>
<p>需要学会查看系统内存 未使用的内容 = free + buffers + cached -m 单位转换M -g 单位转换为G</p>
<h3 id="vmstat">vmstat</h3>
<p>分析系统问题<br>
r (running) 列表运行和等待的进程数量，如果长期大于1说明cpu不足，需要cpu。<br>
b 列表等待资源的进程数，如等待I/O，或者内存交换等。</p>
<p>cpu使用状态<br>
us 表示用户进程cpu时间占比，如果长期大于50%,需要考虑优化用户程序。<br>
sy 显示了内核进程cpu时间占比，如果us + sy 大于80%说明可能存在CPU不足。<br>
wa 显示了IO等待所占用的CPU时间的百分比，说明IO等待严重，磁盘大量随机访问造成的，也可能是磁盘或者磁盘访问控制器带宽瓶颈造成的<br>
id cpu处于空闲的百分比</p>
<p>system显示采集间隔中观察到的每秒设备中断数。<br>
in 列表在某一时间间隔中观察到的每秒设备中断数<br>
cs 表示每秒产生的上下文切换次数</p>
<p>memory 内存情况<br>
swpd 切换到内存交换区的内存数量，如果swpd的值不为0，或者比较大，只要si,so的长期为0，系统性能还是正常<br>
free 当前的空闲页面列表中内存数量(k表示)<br>
buff 作为buffer cache的内存数量，一般对块设备的读写才需要缓冲。<br>
cache 作为page cache的内存数量，一般作为文件系统的cache，如果cache较大，说明用到cache的文件较多，如果此时IO中bi比较小，说明文件系统效率比较好。</p>
<p>swap<br>
si 由内存进入内存交换区数量<br>
so 有内存交换区进入内存数量</p>
<p>IO<br>
bi 从块设备读入数据的总量（读磁盘）（每秒kb）<br>
bo 块设备写入数据的总量(写磁盘)（每秒kb）<br>
这里我们设置的bi+bo参考值为1000，如果超过1000，而且wa值较大应该考虑均衡磁盘负载，可以结合iostat输出来分析。</p>
<h3 id="dd">dd</h3>
<p>模拟读写磁盘操作</p>
<h3 id="top">top</h3>
<p>系统</p>
<h3 id="watch-more-procnetdev">watch more /proc/net/dev</h3>
<p>用于定位丢包，错报情况，以便看望了瓶颈</p>
<h3 id="netstat">netstat</h3>
<p>查看端口</p>
<h3 id="ping">ping</h3>
<h3 id="traceroute-ip">traceroute ip</h3>
<p>路由追踪</p>
<h3 id="dig">dig</h3>
<p>查看域名解析</p>
<h3 id="dmesg">dmesg</h3>
<p>查看系统日志</p>
<h3 id="df">df</h3>
<p>查看磁盘剩余空间</p>
<h3 id="du">du</h3>
<p>查看磁盘使用空间</p>
<h3 id="ps">ps</h3>
<p>查看进程</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[计算机操作系统-链接]]></title>
        <id>https://miexxx.github.io/post/ji-suan-ji-cao-zuo-xi-tong-lian-jie/</id>
        <link href="https://miexxx.github.io/post/ji-suan-ji-cao-zuo-xi-tong-lian-jie/">
        </link>
        <updated>2020-03-31T13:44:40.000Z</updated>
        <content type="html"><![CDATA[<h1 id="编译系统">编译系统</h1>
<p>以下是一个hello.c程序</p>
<pre><code>#include &lt;stdio.h&gt;

int main()
{
    printf(&quot;hello, world\n&quot;);
    return 0;
}

</code></pre>
<p>在Unix系统上，由于编译器把源文件转换为目标文件。</p>
<pre><code>gcc -o hello hello.c
</code></pre>
<p>这个过程大致如下：<br>
<img src="https://camo.githubusercontent.com/e1da518d4b62181167c2b1fea745c9bcc6b44c35/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62333936643732362d623735662d346133322d383961322d3033613762366531396636662e6a7067" alt="" loading="lazy"></p>
<p>预处理阶段：处理以 # 开头的预处理命令；<br>
编译阶段：翻译成汇编文件；<br>
汇编阶段：将汇编文件翻译成可重定位目标文件；<br>
链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。</p>
<h1 id="静态链接">静态链接</h1>
<p>静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：</p>
<p>符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。<br>
重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。<br>
<img src="https://camo.githubusercontent.com/33c7b278162d2fde0df39a36dc9943ff03f9aa05/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34376439383538332d386262302d343563632d383132642d3437656566613061346134302e6a7067" alt="" loading="lazy"></p>
<h1 id="动态链接">动态链接</h1>
<p>静态库有以下两个问题：</p>
<p>当静态库更新时那么整个程序都要重新进行链接；<br>
对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。<br>
共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点：</p>
<p>在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中；<br>
在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。<br>
<img src="https://camo.githubusercontent.com/f684ca99d53f8992733f530d09165309e6f72e87/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f37366463373736392d316161632d343838382d396265612d3036346631636161386537372e6a7067" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[计算机操作系统-设备管理]]></title>
        <id>https://miexxx.github.io/post/ji-suan-ji-cao-zuo-xi-tong-she-bei-guan-li/</id>
        <link href="https://miexxx.github.io/post/ji-suan-ji-cao-zuo-xi-tong-she-bei-guan-li/">
        </link>
        <updated>2020-03-31T13:38:39.000Z</updated>
        <content type="html"><![CDATA[<h1 id="磁盘结构">磁盘结构</h1>
<p>盘面（Platter）：一个磁盘有多个盘面；<br>
磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；<br>
扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；<br>
磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；<br>
制动手臂（Actuator arm）：用于在磁道之间移动磁头；<br>
主轴（Spindle）：使整个盘面转动。</p>
<figure data-type="image" tabindex="1"><img src="https://camo.githubusercontent.com/42c8be3472d81b72762c2a88b29fa61b4bdf2409/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30313466626334642d643837332d346131322d623136302d3836376464616564393830372e6a7067" alt="" loading="lazy"></figure>
<h1 id="磁盘调度算法">磁盘调度算法</h1>
<p>读写一个磁盘块的时间的影响因素有：</p>
<p>旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）<br>
寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）<br>
实际的数据传输时间<br>
其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。</p>
<h2 id="先来先服务">先来先服务</h2>
<p>按照磁盘请求的顺序进行调度。<br>
优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。</p>
<h2 id="最短寻道时间优先">最短寻道时间优先</h2>
<p>优先调度与当前磁头所在磁道距离最近的磁道。</p>
<p>虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。<br>
<img src="https://camo.githubusercontent.com/513755459b87116ae3a03bb9c4c6a0b161e7d0ed/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34653234383565342d333462642d343936372d396630322d3063303933623739376161612e706e67" alt="" loading="lazy"></p>
<h2 id="电梯算法">电梯算法</h2>
<p>电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。<br>
电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。<br>
因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。<br>
<img src="https://camo.githubusercontent.com/8187903788bbfb90978169f20fa4fd41e094bf22/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32373163653038662d633132342d343735662d623439302d6265343466656463366432652e706e67" alt="" loading="lazy"></p>
]]></content>
    </entry>
</feed>